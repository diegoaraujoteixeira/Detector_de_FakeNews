import streamlit as st
import tensorflow as tf
# Importe Keras de tf_keras para compatibilidade com Keras 3
import keras as tf_keras # Adicione esta linha
from tensorflow.keras.layers import TextVectorization, Embedding, GlobalAveragePooling1D, Dense, Dropout, BatchNormalization
# Use load_model de tf_keras
from keras.models import load_model # <--- MUDE PARA 'from keras.models import load_model' ou 'from tf_keras.models import load_model'
# Se voc√™ usou deploy_model.save("fake_news_classifier.keras")
# Voc√™ n√£o precisa mais do Sequential, numpy, pandas, json, os, gdown aqui,
# porque o modelo j√° carrega tudo. Mantenha os imports de Streamlit e TensorFlow
# e as camadas que est√£o na arquitetura do modelo.
import numpy as np # Mantenha se precisar para tf.constant
import pandas as pd # Mantenha para df_results
import json # Mantenha caso queira o vetorizador separado (menos ideal)
import os # Mantenha para verificar existencia de arquivo
import gdown # Mantenha para baixar do Google Drive


# --- Caminhos dos Arquivos Salvos (atualize seus IDs do Drive aqui) ---
MODEL_FILE_NAME = 'fake_news_classifier.keras' # <--- O NOME DO SEU NOVO ARQUIVO!
# Se voc√™ est√° salvando o modelo COMPLETO (com TextVectorization) no formato .keras,
# VOC√ä N√ÉO PRECISA MAIS DO ARQUIVO text_vectorizer_config.json SEPARADO.
# Ent√£o, voc√™ pode COMENTAR/REMOVER VECTORIZER_CONFIG_FILE_NAME e VECTORIZER_DRIVE_ID.
# VECTORIZER_CONFIG_FILE_NAME = 'text_vectorizer_config.json'
# VECTORIZER_DRIVE_ID = 'SEU_ID_DO_VECTORIZER_AQUI'

# **AQUI VOC√ä PRECISA COLOCAR OS IDs CORRETOS DO SEU NOVO ARQUIVO .keras NO GOOGLE DRIVE**
MODEL_DRIVE_ID = 'SEU_NOVO_ID_DO_MODELO_KERAS_AQUI' # <--- NOVO ID DO fake_news_classifier.keras

# --- Fun√ß√µes de Carregamento (simplificadas para o formato .keras) ---

@st.cache_resource
def download_file_from_drive(file_id, output_path):
    if not os.path.exists(output_path):
        st.write(f"Baixando {output_path} do Google Drive...")
        try:
            gdown.download(f'https://drive.google.com/uc?id={file_id}', output_path, quiet=False)
            st.write(f"Download de {output_path} conclu√≠do.")
        except Exception as e:
            st.error(f"Erro ao baixar {output_path} do Google Drive: {e}")
            st.stop()
    else:
        st.write(f"{output_path} j√° existe localmente. Pulando download.")

@st.cache_resource
def load_complete_model(model_path): # Renomeei para indicar que carrega o modelo completo
    download_file_from_drive(MODEL_DRIVE_ID, model_path)
    # Carrega o modelo que j√° inclui a camada TextVectorization
    # Use o load_model do 'keras' ou 'tf_keras' diretamente para Keras 3
    model = load_model(model_path, compile=False) # compile=False ainda √© uma boa pr√°tica
    # O modelo j√° vem com a camada TextVectorization configurada internamente.
    # N√£o precisa mais de recompila√ß√£o do otimizador aqui, pois o modelo completo j√° foi salvo compilado.
    return model

# Remova a fun√ß√£o load_and_adapt_text_vectorizer, pois ela n√£o √© mais necess√°ria

# --- Fun√ß√£o Principal do Aplicativo Streamlit ---
def main():
    st.set_page_config(page_title="Detector de Not√≠cias Falsas")
    st.title('üì∞ Detector de Not√≠cias Falsas')
    st.markdown("Use este aplicativo para verificar se uma not√≠cia √© provavelmente **FALSA** ou **REAL**.")

    st.info("Preparando o detector... Isso pode levar alguns segundos na primeira vez (baixando o modelo).")

    # Carrega o modelo completo. Ele j√° tem o vetorizador integrado.
    full_model = load_complete_model(MODEL_FILE_NAME) # <--- AQUI CARREGA O MODELO COMPLETO

    st.success("Detector pronto! Insira o texto da not√≠cia.")

    st.write("---")
    st.subheader('Cole o texto da not√≠cia aqui:')
    user_news_input = st.text_area("", height=250, placeholder="Ex: Cientistas descobrem cidade perdida em Marte...")

    if st.button('Classificar Not√≠cia'):
        if user_news_input:
            with st.spinner('Analisando not√≠cia...'):
                # A previs√£o agora √© feita diretamente no modelo completo
                # O modelo completo espera um tensor de strings
                prediction_prob = full_model.predict(tf.constant([user_news_input]))[0][0]

                # ... (resto da l√≥gica de exibi√ß√£o permanece o mesmo) ...

                st.subheader("Resultado da An√°lise:")
                if prediction_prob > 0.5:
                    st.success(f"**Esta not√≠cia √© REAL!** (Probabilidade de ser Real: {prediction_prob*100:.2f}%)")
                    st.balloons()
                else:
                    st.error(f"**Esta not√≠cia √© FALSA!** (Probabilidade de ser Falsa: {(1-prediction_prob)*100:.2f}%)")
                    st.snow()

                st.write("---")
                st.subheader("Probabilidades Detalhadas:")
                classes = ['Falsa', 'Real'] # Defina as classes aqui, pois n√£o v√™m do df_results
                probabilities = [(1 - prediction_prob) * 100, prediction_prob * 100]
                df_results = pd.DataFrame({'Classes': classes, 'Probabilidades (%)': probabilities})
                st.dataframe(df_results.set_index('Classes'))

        else:
            st.warning('Por favor, digite ou cole o texto de uma not√≠cia para classificar.')

    st.markdown("---")
    st.write("Desenvolvido com TensorFlow e Streamlit")
    st.write("Para treinar o modelo, execute `python model_trainer.py` e fa√ßa o upload do arquivo `fake_news_classifier.keras` para o Google Drive e atualize o ID neste script.")

if __name__ == "__main__":
    main()
